# OSIPTEL Scraper v1.0

Sistema de scraping automÃ¡tico de lÃ­neas telefÃ³nicas de OSIPTEL por RUC con **auto-detecciÃ³n de recursos del sistema** y **configuraciÃ³n optimizada**.

---

## ğŸš€ Inicio RÃ¡pido

### InstalaciÃ³n AutomÃ¡tica Completa

**Â¡NUEVO!** El instalador ahora incluye **instalaciÃ³n automÃ¡tica de Python** si no lo tienes instalado.

**TODO EN UNO**: Ejecuta el instalador que prepara el entorno completo:

```batch
start.bat
```

El instalador automÃ¡ticamente:
0. âœ… **Verifica e instala Python 3.12** (si no estÃ¡ instalado)
1. âœ… **Verifica la versiÃ³n de Python** (mÃ­nimo 3.10+)
2. âœ… **Crea el entorno virtual** (`venv/`)
3. âœ… **Activa el entorno virtual** 
4. âœ… **Instala todas las dependencias** (camoufox, pandas, aiohttp, psutil, etc.)
5. âœ… **Descarga el browser Camoufox**
6. âœ… **Crea la estructura de carpetas**
7. âœ… **Deja el entorno ACTIVADO** para que ejecutes inmediatamente

**El script es inteligente**:
- Si **NO tienes Python**: Lo descarga e instala automÃ¡ticamente (Python 3.12.10)
- Si **YA tienes Python**: Verifica que sea versiÃ³n 3.10+ y continÃºa con la instalaciÃ³n
- Si tienes una **versiÃ³n antigua**: Te avisa y te indica cÃ³mo actualizarlo

**DespuÃ©s de ejecutar `start.bat`**, en la MISMA ventana ejecuta:

```batch
python run_auto.py rucs/tu_archivo.csv
```

O con lÃ­mite de bandwidth personalizado (en MB):

```batch
python run_auto.py rucs/tu_archivo.csv --bandwidth 5000
```

---

### Para Ejecuciones Futuras

Si cierras la terminal y quieres ejecutar el scraper de nuevo:

```batch
venv\Scripts\activate
python run_auto.py rucs/tu_archivo.csv
```

**Nota**: Solo necesitas ejecutar `start.bat` **UNA VEZ** (primera instalaciÃ³n). DespuÃ©s solo activas el entorno con `venv\Scripts\activate`.

---

## ğŸ“‹ Requisitos

- **Windows 10/11** (64-bit)
- **4GB RAM mÃ­nimo** (recomendado 8GB+)
- **ConexiÃ³n a internet estable**
- **Python 3.10+** - Â¡Ahora se instala automÃ¡ticamente si no lo tienes!

### Notas sobre Python:
- El instalador detecta automÃ¡ticamente si tienes Python instalado
- Si no lo tienes, descarga e instala Python 3.12.10 automÃ¡ticamente
- Si ya tienes Python, verifica que sea versiÃ³n 3.10 o superior
- Versiones recomendadas: Python 3.10, 3.11 o 3.12

---

## ğŸ¯ Modos de EjecuciÃ³n

Al ejecutar `run_auto.py`, se mostrarÃ¡ un menÃº:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       OSIPTEL SCRAPER v1.0 - MODO DE EJECUCIÃ“N                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Selecciona el modo de configuraciÃ³n de workers:

  [1] AutomÃ¡tico - Analizar PC y asignar workers automÃ¡ticamente
  [2] Manual     - Especificar cantidad de workers manualmente
```

### Modo AutomÃ¡tico (Recomendado)

El sistema analiza automÃ¡ticamente:
- **CPU**: Detecta nÃºcleos fÃ­sicos disponibles
- **RAM**: Calcula memoria disponible (2GB por worker)
- **Red**: Mide latencia al proxy y ajusta delays

Ejemplo de detecciÃ³n:

```
âš¡ RECURSOS DEL SISTEMA DETECTADOS:
   CPU:               8 cores (fÃ­sicos)
   RAM disponible:    5.9 GB
   Latencia proxy:    270 ms
   
âš¡ CONFIGURACIÃ“N Ã“PTIMA:
   Workers paralelos: 12
   Delay min-max:     1.0s - 2.0s
   PÃ¡ginas/browser:   150
```

### Modo Manual

Te permite especificar la cantidad exacta de workers (1-50).

Ãštil si:
- Quieres forzar menos workers para ahorrar recursos
- Conoces la capacidad Ã³ptima de tu PC
- Necesitas probar diferentes configuraciones

---

## ğŸ“ Formato del Archivo de RUCs

El archivo CSV debe tener los RUCs en la **primera columna** con header "RUC":

```csv
RUC
20100047218
20100130204
20293847560
```

- Los RUCs deben tener exactamente **11 dÃ­gitos**
- Formato: CSV (separado por comas)

---

## ğŸ“¤ Archivos de Salida

Todos los resultados se guardan en `osiptel_output/`:

| Archivo | DescripciÃ³n |
|---------|-------------|
| `resultados.csv` | Datos extraÃ­dos (RUC + lÃ­neas telefÃ³nicas) |
| `save/*.csv` | Guardados parciales automÃ¡ticos |
| `performance_report.json` | Reporte detallado de rendimiento |
| `scraper.log` | Log completo de ejecuciÃ³n |

### Formato de Resultados

```csv
RUC,Modalidad_1,Numero_Telefonico_1,Empresa_Operadora_1,Modalidad_2,...
20100047218,MOVIL,987654321,MOVISTAR,FIJO,014567890,CLARO
20100130204,MOVIL,912345678,ENTEL,,,,
20293847560,,,,,,,
```

Si un RUC no tiene lÃ­neas registradas, aparece con campos vacÃ­os.

---

## âš™ï¸ ConfiguraciÃ³n del Proxy

Edita `config.py` con tus credenciales de SmartProxy:

```python
# Credenciales SmartProxy
PROXY_HOST = "proxy.smartproxy.net"
PROXY_PORT = 3120
PROXY_USERNAME = "smart-haroldvpn_area-PE"  # Tu usuario con _area-PE
PROXY_PASSWORD = "tu_contraseÃ±a"

# LÃ­mites
MAX_BANDWIDTH_MB = 99000  # 99GB (ajusta segÃºn tu plan)
MAX_WORKERS = 12  # Fallback si la detecciÃ³n automÃ¡tica falla
```

**IMPORTANTE**: El formato del username es crÃ­tico:
- Debe incluir `_area-PE` al final para obtener IPs de PerÃº
- Ejemplo: `smart-haroldvpn_area-PE`

---

## ğŸ”§ Opciones Avanzadas

### Ajustar LÃ­mite de Bandwidth

Por defecto el scraper intenta usar hasta 10GB por ejecuciÃ³n:

```batch
# Usar solo 5GB
python run_auto.py rucs/archivo.csv --bandwidth 5000

# Usar 20GB
python run_auto.py rucs/archivo.csv --bandwidth 20000
```

### Cambiar Directorio de Salida

```batch
python run_auto.py rucs/archivo.csv --output mis_resultados/
```

### Probar ConexiÃ³n al Proxy

Antes de ejecutar un scraping masivo, verifica la conexiÃ³n:

```batch
python test_proxy.py
```

---

## ğŸ”„ ReanudaciÃ³n AutomÃ¡tica

Si el scraping se interrumpe (Ctrl+C, error, lÃ­mite de bandwidth), el sistema:

1. **Guarda todo el progreso** automÃ¡ticamente
2. **Elimina los RUCs procesados** del archivo CSV original
3. **Crea un backup** del archivo original en `rucs/backups/`

Para continuar, simplemente ejecuta de nuevo:

```batch
python run_auto.py rucs/archivo.csv
```

El scraper detectarÃ¡ que hay RUCs pendientes y continuarÃ¡ desde donde quedÃ³.

---

## ğŸ“Š Rendimiento Esperado

Con configuraciÃ³n automÃ¡tica Ã³ptima (12 workers):

| RUCs | Tiempo estimado |
|------|-----------------|
| 1,000 | ~1.5 horas |
| 5,000 | ~8 horas |
| 10,000 | ~16 horas |
| 20,000 | ~33 horas |

**Nota**: El tiempo varÃ­a segÃºn:
- Recursos del sistema (CPU, RAM)
- Velocidad de conexiÃ³n a internet
- Latencia al proxy
- Cantidad de lÃ­neas por RUC

---

## ğŸ›¡ï¸ CaracterÃ­sticas de Seguridad

### Anti-DetecciÃ³n
- **Camoufox**: Browser anti-detecciÃ³n basado en Firefox
- **RotaciÃ³n de sesiones**: Cada worker usa sesiÃ³n Ãºnica del proxy
- **Delays aleatorios**: Entre requests para simular comportamiento humano
- **Fingerprint humanizado**: User agents y configuraciones realistas

### GestiÃ³n de Errores
- **Reintentos automÃ¡ticos**: Hasta 2 intentos por RUC
- **DetecciÃ³n de bandwidth**: Se detiene automÃ¡ticamente al alcanzar lÃ­mite
- **Guardado periÃ³dico**: Progreso guardado cada 25 RUCs
- **Manejo de interrupciones**: Ctrl+C guarda estado actual

---

## ğŸ“ Estructura del Proyecto

```
osiptel-scraper-v1/
â”œâ”€â”€ run_auto.py           # ğŸš€ Script principal de ejecuciÃ³n
â”œâ”€â”€ system_optimizer.py   # âš¡ Auto-detecciÃ³n de recursos
â”œâ”€â”€ osiptel_main.py       # ğŸ¯ Orquestador de workers
â”œâ”€â”€ osiptel_worker.py     # ğŸ‘· LÃ³gica de scraping
â”œâ”€â”€ osiptel_core.py       # ğŸ“¦ Clases base y utilidades
â”œâ”€â”€ config.py             # âš™ï¸ ConfiguraciÃ³n (EDITAR AQUÃ)
â”œâ”€â”€ start.bat             # ğŸ”§ Instalador de dependencias
â”œâ”€â”€ requirements.txt      # ğŸ“‹ Lista de dependencias
â”œâ”€â”€ .gitignore            # ğŸš« Archivos ignorados por Git
â”œâ”€â”€ venv/                 # ğŸ Entorno virtual (creado por start.bat)
â”œâ”€â”€ rucs/                 # ğŸ“‚ Carpeta para archivos CSV (CREAR MANUALMENTE)
â”‚   â”œâ”€â”€ tu_archivo.csv    # Tu archivo con RUCs a scrapear
â”‚   â””â”€â”€ backups/          # ğŸ’¾ Backups automÃ¡ticos (creado automÃ¡ticamente)
â””â”€â”€ osiptel_output/       # ğŸ“¤ Resultados del scraping (creado automÃ¡ticamente)
    â”œâ”€â”€ resultados.csv    # Datos extraÃ­dos
    â”œâ”€â”€ save/             # Guardados parciales
    â”œâ”€â”€ performance_report.json
    â””â”€â”€ scraper.log
```

### ğŸ“‹ Carpetas que debes crear manualmente:

**IMPORTANTE**: Antes de ejecutar el scraper, crea la carpeta `rucs/`:

```batch
mkdir rucs
```

Luego coloca tu archivo CSV con los RUCs dentro de `rucs/`.

### ğŸ¤– Carpetas creadas automÃ¡ticamente:

- âœ… `venv/` - Creada por `start.bat`
- âœ… `osiptel_output/` - Creada al ejecutar el scraper
- âœ… `rucs/backups/` - Creada al procesar RUCs

---

## ğŸ”§ SoluciÃ³n de Problemas

### "Failed to create browser"

**Causa**: Error en la instalaciÃ³n de Camoufox.

**SoluciÃ³n**:
```batch
python -m camoufox fetch
```

### "Proxy connection failed"

**Causa**: Credenciales incorrectas o proxy no disponible.

**SoluciÃ³n**:
1. Verifica `config.py` con tus credenciales correctas
2. Ejecuta `python test_proxy.py` para validar
3. Verifica tu plan en dashboard.smartproxy.com

### "NotImplementedError in subprocess_exec"

**Causa**: PolÃ­tica de event loop incorrecta (ya corregido en v1.0).

**SoluciÃ³n**: Usa la versiÃ³n actual de `run_auto.py` que no establece `WindowsSelectorEventLoopPolicy`.

### Muchos RUCs fallan

**SoluciÃ³n**:
1. Usa modo manual con menos workers (ej: 8)
2. Verifica que los RUCs tengan 11 dÃ­gitos
3. Revisa el log en `osiptel_output/scraper.log`

### Scraper muy lento

**SoluciÃ³n**:
1. Verifica tu conexiÃ³n a internet
2. Prueba con modo manual y mÃ¡s workers
3. Reduce el valor de `MAX_RETRIES` en `osiptel_core.py`

---

## ğŸ“ˆ EstimaciÃ³n de Bandwidth

Cada RUC consume aproximadamente **0.5-1 MB** en promedio (con `BLOCK_IMAGES=True`).

| Plan | Bandwidth | RUCs aproximados |
|------|-----------|------------------|
| 10 GB | 10,000 MB | ~15,000 RUCs |
| 25 GB | 25,000 MB | ~40,000 RUCs |
| 50 GB | 50,000 MB | ~80,000 RUCs |
| 100 GB | 100,000 MB | ~160,000 RUCs |

**RecomendaciÃ³n**: Siempre deja un buffer de 5-10% para evitar cortes abruptos.

---

## ğŸ› ï¸ Dependencias Instaladas

El archivo `requirements.txt` incluye:

```
camoufox>=0.4.11      # Browser anti-detecciÃ³n
aiofiles>=24.0.0      # Operaciones de archivos async
aiohttp>=3.10.0       # Cliente HTTP async
pandas>=2.2.0         # Procesamiento de datos
openpyxl>=3.1.0       # Lectura/escritura Excel
psutil>=6.0.0         # Monitoreo del sistema
```

---

## ğŸ“ Obtener Credenciales SmartProxy

1. Registrate en [smartproxy.com](https://smartproxy.com)
2. Compra un plan de Residential Proxies
3. Ve a Dashboard â†’ Residential Proxies â†’ Proxy Setup
4. Copia tus credenciales:
   - **Username**: Formato `smart-usuario_area-PE`
   - **Password**: Tu contraseÃ±a
   - **Host**: `proxy.smartproxy.net`
   - **Port**: `3120` (residential)

---

## ğŸ“ Changelog

### v1.0 (2026-01-17)
- âœ… Auto-detecciÃ³n de recursos del sistema
- âœ… MenÃº interactivo (modo automÃ¡tico vs manual)
- âœ… Instalador simplificado (solo Windows)
- âœ… EliminaciÃ³n automÃ¡tica de RUCs procesados
- âœ… Reportes JSON detallados
- âœ… Filtro de 100 registros por pÃ¡gina implementado
- âœ… Fix: Event loop policy corregido para Windows

---

*OSIPTEL Scraper v1.0 - Optimizado para Windows*
